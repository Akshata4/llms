{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4f3f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "483f5d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc766fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Akshata is a data engineer'] <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "text = 'Akshata is a data engineer'\n",
    "# documents = Document(page_content=text)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"]\n",
    ")\n",
    "# docs = [Document(**d) for d in documents]\n",
    "\n",
    "chunks = text_splitter.split_text(text)\n",
    "\n",
    "print(chunks, type(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3cf4771",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",  # Use a standard embedding model name\n",
    "    # openai_api_key=api_key,\n",
    "    # openai_api_base=\"https://api.openai.com/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a379b697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.embeddings.Embeddings object at 0x7a8606729460> async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x7a86070e6330> model='text-embedding-3-large' dimensions=None deployment='text-embedding-ada-002' openai_api_version=None openai_api_base=None openai_api_type=None openai_proxy=None embedding_ctx_length=8191 openai_api_key=SecretStr('**********') openai_organization=None allowed_special=None disallowed_special=None chunk_size=1000 max_retries=2 request_timeout=None headers=None tiktoken_enabled=True tiktoken_model_name=None show_progress_bar=False model_kwargs={} skip_empty=False default_headers=None default_query=None retry_min_seconds=4 retry_max_seconds=20 http_client=None http_async_client=None check_embedding_ctx_length=True\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d3b43a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = InMemoryVectorStore.from_texts(\n",
    "    chunks,\n",
    "    embeddings_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a80582a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_core.vectorstores.in_memory.InMemoryVectorStore object at 0x7a86045b4c50> <class 'langchain_core.vectorstores.in_memory.InMemoryVectorStore'>\n"
     ]
    }
   ],
   "source": [
    "print(vectorstore, type(vectorstore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b078c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-5-mini\",  # or another suitable model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5713a365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You told me Akshata is a data engineer. With only that fact, here’s a useful, general description of what that likely means and what Akshata might do or know — if you want a more specific summary, tell me more about her experience, tools, or industry.\n",
      "\n",
      "What being a data engineer typically implies\n",
      "- Role focus: building, maintaining, and optimizing the systems that collect, store, and transport data so analysts and ML engineers can use it.\n",
      "- Responsibilities: designing ETL/ELT pipelines, ingesting data from multiple sources, cleaning and transforming data, ensuring data quality and reliability, and implementing data storage solutions (data warehouses, data lakes).\n",
      "- Common tools & technologies: SQL, Python or Scala, Apache Spark, Kafka, Airflow, dbt, AWS/GCP/Azure cloud services (S3, Redshift, BigQuery, Dataproc, etc.), Docker, Kubernetes, and monitoring tools.\n",
      "- Data modeling & architecture: designing schemas, partitioning strategies, and metadata/catalog solutions; working on performance tuning for queries and pipelines.\n",
      "- Testing & observability: unit/integration tests for pipelines, data validation checks, logging, alerting, and lineage tracking.\n",
      "- Collaboration: works closely with data analysts, data scientists, ML engineers, product managers, and software engineers to understand data requirements and deliver usable datasets.\n",
      "- Skills beyond code: strong problem-solving, attention to detail, system design thinking, and communication skills to explain data constraints and trade-offs.\n",
      "- Typical background & career path: often comes from computer science, engineering, or related fields; career can progress to senior data engineer, data architect, platform engineering, or leadership roles in data teams.\n",
      "\n",
      "If you want a short bio of Akshata for a resume, LinkedIn, or an internal profile, give me her level (junior/senior), key tools she uses, and any notable projects or industries, and I’ll draft one.\n"
     ]
    }
   ],
   "source": [
    "query = \"tell me about Akshata\"\n",
    "\n",
    "# Retrieve relevant documents from the vectorstore\n",
    "retrieved_docs = vectorstore.similarity_search(query, k=2)\n",
    "\n",
    "# Prepare context from retrieved documents\n",
    "context = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "# Create a prompt grounded in the retrieved context\n",
    "prompt = f\"Based on the following information:\\n{context}\\n\\nAnswer the question: {query}\"\n",
    "\n",
    "# Get response from the LLM\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d60500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f836cfa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9128b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab81abdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aab52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6a55c9f",
   "metadata": {},
   "source": [
    "## Learnings from Ankur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e71ab542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(26, 43), match='akshata@gmail.com'>\n",
      "Akshata is a pretty girl\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me all details about akshata@gmail.com?\"\n",
    "\n",
    "def get_details(email):\n",
    "    # Simulate fetching details from a database or API\n",
    "    details = {\n",
    "        \"akshata@gmail.com\" : \"Akshata is a pretty girl\",\n",
    "        \"ankur@gmail.com\": \"Ankur is a bad boy\"}\n",
    "    \n",
    "    return details.get(email, \"No details found for this email.\")\n",
    "\n",
    "import re\n",
    "\n",
    "email_regex = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "email_match = re.search(email_regex, query)\n",
    "print(email_match)\n",
    "if email_match:\n",
    "    email = email_match.group(0)\n",
    "    details = get_details(email)\n",
    "    print(details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47afe3a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3898003474.py, line 11)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdistances[record[\"id\"]] = similarity_vec(query_vector, record[\"embedding\"]) + similarity_keyword(query, record[])\u001b[39m\n                                                                                                            ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "vector_store = [\n",
    "    {\"id\": 1, \"text\": \"ranodm text about\", \"metadata\": {\"source\": \"doc1.txt\"}, \"embedding\": [0.1, 0.2, 0.3]},\n",
    "    {\"id\": 2, \"text\": \"akshata is a\", \"metadata\": {\"source\": \"doc2.txt\"}, \"embedding\": [0.4, 0.5, 0.6]},\n",
    "]\n",
    "\n",
    "search_query = \"akshata\"\n",
    "def search_vector_store(query, k=5):\n",
    "    query_vector = embedding_model(query) # [0.1, 08, 0.9]\n",
    "    distances = {}\n",
    "    for record in vector_store.filter({\"metadata\":{\"userID\": \"akshata\"}}):\n",
    "        distances[record[\"id\"]] = 0.8* similarity_vec(query_vector, record[\"embedding\"]) + (1-0.8)*similarity_keyword(query, record[\"text\"])\n",
    "    \n",
    "    # distance = {1: 0.8, 2:0.9}\n",
    "    topk = sorted(distances.items(), lambda x: x[1], reverse=True)[:k]\n",
    "    return topk # [(vector_store[2], 0.9), (vector_store[1], 0.8)]\n",
    "\n",
    "context = \"\"\n",
    "for records in topk:\n",
    "    context += \"\\n\\n\" + records[0][\"text\"]\n",
    "\n",
    "search_query + context = \"ranodm text about \\n\\n akshata is a\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0977142a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
